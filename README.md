# Chess-AI

Chess-AI 是一个基于蒙特卡罗树搜索（MCTS）和深度学习的国际象棋人工智能模型。模型通过自我对弈来逐步提升决策能力，结合搜索树结构与神经网络，生成每个节点的策略（P值）和价值（V值），并利用这些指标选择最佳棋步。

## 模型结构

模型的核心是一个巨大的搜索树，每个节点代表一个棋局状态。黑白双方轮流走棋，树上的每个节点包含以下几个重要的参数：

- **N**：节点的访问次数 + 1
- **W**：节点的总得分
- **Q**：节点的平均得分，计算公式为 W / N
- **P**：子节点的访问比例，反映父节点对子节点的偏好
- **U**：节点的欠搜索程度，公式为 k * P * sqrt(N') / N，其中 N' 为同一父节点下的子节点访问次数总和
- **V**：节点的价值，由模型预测

## 训练过程

### 第一阶段：深度优先搜索

在第一阶段，模型进行100,000轮深度优先的自我对弈。通过游戏结果（胜/负/平）来更新节点的得分和访问次数：

- 对于叶子节点（最终游戏结果确定），根据胜负（胜为1，负为-1，平局为0）更新该节点及其祖先节点的W值。
- 每次访问节点时，N值增加1，W值累加胜负结果。

### 第二阶段：价值网络训练与多线程优化

第二阶段的训练没有明确的上限，模型会不断优化。在这一阶段：

- **选择节点**：模型根据 V + U 的和来选择节点，其中 U 值考虑了节点的欠搜索程度。
- **更新节点**：如果选择的是叶子节点，依据游戏结果（1/0/-1）更新W值，若选择的是中间节点，依据V值更新W值。
- **多线程训练**：使用多线程并行训练，避免单线程的训练瓶颈，同时通过随机噪声引入更多多样性，提升探索性。

每训练一万次，模型会暂停并重新训练V值，以确保V值能随着游戏结果的变化而更精确。

### 视角调整

为了适应黑方的输入，棋盘状态在黑方使用时会进行旋转。这样，无论是白方还是黑方使用模型，都能正确评估局面。

## 输入与输出

- **输入**：模型的输入为一个 8x8x12 的三维矩阵，表示棋盘的状态。每个棋子（白方或黑方的王、后、车、马、象、兵）通过一个 8x8 的二维矩阵来表示。若某位置上有该棋子，矩阵值为1，否则为0。
- **输出**：模型输出每个子节点的 P 值（该棋步的概率）和 V 值（该局面的价值）。P 值用于指导棋局的策略选择，V 值则是对局势的价值评估。

## 数据保存

模型将对局数据保存为 CSV 格式，以便后续分析和训练。这些数据包含节点的 P 值、V 值和其他重要指标，可以用于优化训练过程。

## 训练流程

1. **第一阶段**：
   - 使用深度优先搜索进行 100,000 轮自我对弈。
   - 根据游戏的输赢结果更新节点的 W、N、Q、P、U 等参数。
   - 该阶段的 V 值与 Q 值一致。

2. **第二阶段**：
   - 选择节点时根据 V + U 的和，进行多线程训练。
   - 每训练 10,000 次后，暂停并重新训练 V 值。
   - 引入随机噪声和死锁保护，确保多线程训练的多样性和稳定性。
